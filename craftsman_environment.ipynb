{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taikatou/economy-monte-carlo/blob/main/craftsman_environment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UerCAbtty4B0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gym import spaces, Env\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "id": "yORkonp5EyKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95bea7d-73c6-42d1-9469-2ee195c1321e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.2.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.1.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.0)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra])\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra])\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=e8e63e1eadca606f4b8ab3f3cdd248754fadcaebbb1a393ab246351245fe2f2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: farama-notifications, gymnasium, ale-py, shimmy, AutoROM.accept-rom-license, autorom, stable-baselines3\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 farama-notifications-0.0.4 gymnasium-0.29.1 shimmy-1.3.0 stable-baselines3-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j-dKf-KC6DXQ"
      },
      "outputs": [],
      "source": [
        "from enum import IntEnum\n",
        "\n",
        "class ResourceType(IntEnum):\n",
        "    WOOD = 1\n",
        "    METAL = 2\n",
        "    GEM = 3\n",
        "    DRAGONSCALE = 4\n",
        "\n",
        "class SwordType(IntEnum):\n",
        "    BEGINNER = 1\n",
        "    INTERMEDIATE = 2\n",
        "    ADVANCED = 3\n",
        "    EPIC = 4\n",
        "    ULTIMATE = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MarketPricing:\n",
        "    def __init__(self, price_increase_factor=0.1, min_price=0.5):\n",
        "        self.resource_prices = {}\n",
        "        self.sword_prices = {}\n",
        "        self.price_increase_factor = price_increase_factor\n",
        "        self.min_price = min_price\n",
        "        self.reset()\n",
        "\n",
        "    def update_resource_price(self, resource_type):\n",
        "        if resource_type in self.resource_prices:\n",
        "            # Increase price by a factor, ensuring it doesn't fall below the minimum price\n",
        "            self.resource_prices[resource_type] = min(\n",
        "                self.min_price,\n",
        "                self.resource_prices[resource_type] * (1 - self.price_increase_factor)\n",
        "            )\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset prices to initial values or any logic you define for resetting the market\n",
        "        self.resource_prices = {\n",
        "            ResourceType.WOOD: 1.0,\n",
        "            ResourceType.METAL: 1.0,\n",
        "            ResourceType.GEM: 1.0,\n",
        "            ResourceType.DRAGONSCALE: 1.0\n",
        "        }\n",
        "        self.sword_prices = {\n",
        "            SwordType.BEGINNER: 10.0,\n",
        "            SwordType.INTERMEDIATE: 12.0,\n",
        "            SwordType.ADVANCED: 14.0,\n",
        "            SwordType.EPIC: 16.0,\n",
        "            SwordType.ULTIMATE: 18.0,\n",
        "        }\n",
        "\n",
        "    def update_sword_price(self, sword_type):\n",
        "        # Increase sword price based on demand\n",
        "        if sword_type in self.sword_prices:\n",
        "            # Increase price by a factor, ensuring it doesn't fall below the minimum price\n",
        "            self.sword_prices[sword_type] = min(\n",
        "                self.max_price,\n",
        "                self.sword_prices[sword_type] * (1 + self.price_increase_factor)\n",
        "            )\n",
        "\n",
        "    def simulate_market_crash(self, crash_factor):\n",
        "        # Decrease prices dramatically to simulate a market crash\n",
        "        for resource_type in self.resource_prices:\n",
        "            self.resource_prices[resource_type] *= crash_factor\n",
        "\n",
        "        for sword_type in self.sword_prices:\n",
        "            self.sword_prices[sword_type] *= crash_factor\n",
        "\n",
        "    def get_resource_prices(self):\n",
        "        return self.resource_prices\n",
        "\n",
        "    def get_sword_prices(self):\n",
        "        return self.sword_prices\n",
        "\n",
        "    def update_prices(self):\n",
        "        # Decrease prices for resources\n",
        "        for resource_type, price in self.resource_prices.items():\n",
        "            decrease_amount = np.random.uniform(-self.price_decrease_factor, self.price_decrease_factor)\n",
        "            self.resource_prices[resource_type] = max(self.min_price, min(self.max_price, price + decrease_amount))\n",
        "        output = str(self.sword_prices)\n",
        "        # Decrease prices for swords\n",
        "        for sword_type, price in self.sword_prices.items():\n",
        "            decrease_amount = np.random.uniform(-self.price_decrease_factor, self.price_decrease_factor)\n",
        "            self.sword_prices[sword_type] = max(self.min_price, min(self.max_price, price + decrease_amount))\n",
        "        # print(output + \"\\t\" + str(self.sword_prices))\n",
        "        # Record the prices after update\n",
        "        self.price_history['resource_prices'].append(self.resource_prices.copy())\n",
        "        self.price_history['sword_prices'].append(self.sword_prices.copy())"
      ],
      "metadata": {
        "id": "SngvFEdv2Ufl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T7DY07hWzOdF"
      },
      "outputs": [],
      "source": [
        "class MarketplaceEnv:\n",
        "    def __init__(self, price_increase_factor=0.01, price_decrease_factor=0.05, min_price=0.5, max_price=100):\n",
        "        self.price_increase_factor = price_increase_factor\n",
        "        self.price_decrease_factor = price_decrease_factor\n",
        "        self.min_price = min_price\n",
        "        self.max_price = max_price\n",
        "        self.resource_prices = {}\n",
        "        self.sword_prices = {}\n",
        "        self.reset()\n",
        "        self.price_history = {\n",
        "            'resource_prices': [],\n",
        "            'sword_prices': []\n",
        "        }\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset prices to initial values or any logic you define for resetting the market\n",
        "        self.resource_prices = {\n",
        "            ResourceType.WOOD: 1.0,\n",
        "            ResourceType.METAL: 1.0,\n",
        "            ResourceType.GEM: 1.0,\n",
        "            ResourceType.DRAGONSCALE: 1.0\n",
        "        }\n",
        "        self.sword_prices = {\n",
        "            SwordType.BEGINNER: 10.0,\n",
        "            SwordType.INTERMEDIATE: 12.0,\n",
        "            SwordType.ADVANCED: 14.0,\n",
        "            SwordType.EPIC: 16.0,\n",
        "            SwordType.ULTIMATE: 18.0,\n",
        "        }\n",
        "\n",
        "    def get_sword_price(self, sword_type):\n",
        "        return self.sword_prices[sword_type]\n",
        "\n",
        "    def get_resource_prices(self):\n",
        "        return self.resource_prices\n",
        "\n",
        "    def update_prices(self):\n",
        "        # Decrease prices for resources\n",
        "        for resource_type, price in self.resource_prices.items():\n",
        "            decrease_amount = np.random.uniform(-self.price_decrease_factor, self.price_decrease_factor)\n",
        "            self.resource_prices[resource_type] = max(self.min_price, price + decrease_amount)\n",
        "        output = str(self.sword_prices)\n",
        "        # Decrease prices for swords\n",
        "        for sword_type, price in self.sword_prices.items():\n",
        "            decrease_amount = np.random.uniform(-self.price_decrease_factor, self.price_decrease_factor)\n",
        "            self.sword_prices[sword_type] = max(self.min_price, price + decrease_amount)\n",
        "        # print(output + \"\\t\" + str(self.sword_prices))\n",
        "        # Record the prices after update\n",
        "        self.price_history['resource_prices'].append(self.resource_prices.copy())\n",
        "        self.price_history['sword_prices'].append(self.sword_prices.copy())\n",
        "\n",
        "    def update_resource_price(self, resource_type):\n",
        "        if resource_type in self.resource_prices:\n",
        "            # Increase price by a factor, ensuring it doesn't fall below the minimum price\n",
        "            self.resource_prices[resource_type] = min(\n",
        "                self.min_price,\n",
        "                self.resource_prices[resource_type] * (1 - self.price_increase_factor)\n",
        "            )\n",
        "\n",
        "    def simulate_market_crash(self, crash_factor=0.5):\n",
        "        # Assume crash_factor is the percentage by which the market crashes, e.g., prices are halved\n",
        "        for resource_type in self.resource_prices:\n",
        "            self.resource_prices[resource_type] *= crash_factor\n",
        "\n",
        "        for sword_type in self.sword_prices:\n",
        "            self.sword_prices[sword_type] *= crash_factor\n",
        "\n",
        "    def update_sword_price(self, sword_type):\n",
        "        if sword_type in self.sword_prices:\n",
        "            # Increase price by a factor, ensuring it doesn't fall below the minimum price\n",
        "            self.sword_prices[sword_type] = min(\n",
        "                self.max_price,\n",
        "                self.sword_prices[sword_type] * (1 + self.price_increase_factor)\n",
        "            )\n",
        "\n",
        "    def give_resource(self, resource_type, inventory):\n",
        "        if resource_type in self.resource_prices:\n",
        "            cost = self.resource_prices[resource_type]\n",
        "            inventory.add_item(resource_type, 1)\n",
        "            return cost\n",
        "        return 0\n",
        "\n",
        "# Initialize the shared marketplace environment\n",
        "marketplace_env = MarketplaceEnv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BGGAaQ-Hoc2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02629e7b-8860-4cc2-8e87-0c5fda61312d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'resource_prices': [], 'sword_prices': []}\n"
          ]
        }
      ],
      "source": [
        "print(marketplace_env.price_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HJT50YGg0yay"
      },
      "outputs": [],
      "source": [
        "class Inventory:\n",
        "    def __init__(self, crafting_requirements):\n",
        "        self.resources = {}\n",
        "        self.swords = {}\n",
        "        self.sale_account = {}\n",
        "        self.crafting_requirements = crafting_requirements\n",
        "        self.reset()\n",
        "\n",
        "    def set_crafting_requirements(self, new_requirements):\n",
        "        self.crafting_requirements = new_requirements\n",
        "\n",
        "    def add_item(self, item, quantity=1):\n",
        "        if item in self.resources:\n",
        "            self.resources[item] += quantity\n",
        "        else:\n",
        "            self.resources[item] = quantity\n",
        "\n",
        "    def reset(self):\n",
        "        self.resources = {ResourceType.WOOD: 0,\n",
        "                          ResourceType.METAL: 0,\n",
        "                          ResourceType.GEM: 0,\n",
        "                          ResourceType.DRAGONSCALE: 0}\n",
        "        self.swords = {SwordType.BEGINNER: 0,\n",
        "                        SwordType.INTERMEDIATE: 0,\n",
        "                        SwordType.ADVANCED: 0,\n",
        "                        SwordType.EPIC: 0,\n",
        "                        SwordType.ULTIMATE: 0}\n",
        "\n",
        "    def craft(self, item):\n",
        "        if item in self.crafting_requirements:\n",
        "            # Check if there are enough resources to craft the item\n",
        "            for resource, amount_required in self.crafting_requirements[item].items():\n",
        "                if self.resources[resource] < amount_required:\n",
        "                    return False  # Not enough resources to craft the item\n",
        "\n",
        "            # Deduct resources used for crafting\n",
        "            for resource, amount_required in self.crafting_requirements[item].items():\n",
        "                self.resources[resource] -= amount_required\n",
        "\n",
        "            # Add the crafted item to the inventory\n",
        "            self.swords[item] += 1\n",
        "            return True\n",
        "        else:\n",
        "            return False  # Item cannot be crafted (not in crafting requirements)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rKHjpD1O1_-w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dv1sHmJlzXtA"
      },
      "outputs": [],
      "source": [
        "class CraftingSellingEnv(Env):\n",
        "    def __init__(self, marketplace_env, crafting_requirements):\n",
        "        super(CraftingSellingEnv, self).__init__()\n",
        "        self.marketplace_env = marketplace_env\n",
        "        self.action_space = spaces.MultiDiscrete([5, 6])  # Resource collection and crafting/selling actions\n",
        "\n",
        "        self.resources = np.zeros(4, dtype=np.int32)\n",
        "        self.money = 100.0  # Starting money\n",
        "        self.inventory = Inventory(crafting_requirements)\n",
        "        # Define the observation space (flattened)\n",
        "        num_resources = 4  # Number of resources\n",
        "        num_swords = 5  # Number of sword types\n",
        "        num_resource_prices = 4  # Number of market prices for resources\n",
        "        num_swords_prices = 5  # Number of market prices for resources\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(num_resources + num_resource_prices + num_swords_prices + 1,), dtype=np.float32)\n",
        "\n",
        "    def cooperative_crafting(self, partner_env, item_to_craft):\n",
        "        # Check if both agents have the required resources for a joint craft\n",
        "        own_requirements_met = all(self.inventory.items[res] >= req for res, req in self.inventory.crafting_requirements[item_to_craft].items())\n",
        "        partner_requirements_met = all(partner_env.inventory.items[res] >= req for res, req in partner_env.inventory.crafting_requirements[item_to_craft].items())\n",
        "\n",
        "        if own_requirements_met and partner_requirements_met:\n",
        "            # Craft the item and share the rewards\n",
        "            self.inventory.craft(item_to_craft)\n",
        "            partner_env.inventory.craft(item_to_craft)\n",
        "            shared_reward = self.marketplace_env.get_sword_price(SwordType[item_to_craft]) / 2\n",
        "            return shared_reward\n",
        "        return 0\n",
        "\n",
        "    def step(self, action):\n",
        "        self.marketplace_env.update_prices()\n",
        "        resource_action, sell_action = action\n",
        "        resources_chosen = [False] * 4\n",
        "        reward = -0.005\n",
        "\n",
        "        if resource_action > 0:\n",
        "            resource_type = ResourceType(resource_action)\n",
        "            cost = self.marketplace_env.give_resource(resource_type, self.inventory)\n",
        "            self.marketplace_env.update_resource_price(resource_type)\n",
        "            self.money -= cost  # Deduct the cost of the resource from the agent's money\n",
        "            reward -= cost  # Decrement reward by the cost of the resource\n",
        "\n",
        "        # Placeholder for reward and done logic\n",
        "\n",
        "        done = False\n",
        "        if sell_action > 0:\n",
        "            sword = SwordType(sell_action)\n",
        "            self.inventory.craft(sword)\n",
        "            if self.inventory.swords[sword] > 0:\n",
        "                income = self.sell_sword(sword)\n",
        "                self.marketplace_env.update_sword_price(sword)\n",
        "                reward += income\n",
        "\n",
        "                # Check if the sold sword is an ULTIMATE_SWORD\n",
        "                if sell_action == SwordType.ULTIMATE:\n",
        "                    done = True  # Set done to True if an Ultimate Sword is sold\n",
        "\n",
        "        return self._get_obs(), reward, done, {}\n",
        "\n",
        "    def sell_sword(self, sword_type):\n",
        "        self.inventory.swords[sword_type] -= 1  # Remove one sword from inventory\n",
        "        selling_price = self.marketplace_env.get_sword_price(sword_type)\n",
        "        self.money += selling_price  # Add money to the wallet based on current price\n",
        "        return selling_price  # Return the income from selling the sword\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.resources = np.zeros(4, dtype=np.int32)\n",
        "        self.money = 100.0\n",
        "        self.inventory.reset()\n",
        "        self.marketplace_env.reset()\n",
        "        return self._get_obs()\n",
        "\n",
        "    def _get_obs(self):\n",
        "        # Flatten all observations into a single array\n",
        "        resource_obs = np.array(list(self.inventory.resources.values()))  # First 4 are resources\n",
        "        resource_prices_obs = np.array(list(self.marketplace_env.get_resource_prices().values()))\n",
        "        sword_prices_obs = np.array(list(self.marketplace_env.sword_prices.values()))\n",
        "        money_obs = np.array([self.money])\n",
        "        observations = np.concatenate((resource_obs, resource_prices_obs, sword_prices_obs, money_obs), axis=0)\n",
        "        return observations\n",
        "\n",
        "    def calculate_efficiency_metrics(self):\n",
        "        # Assume we have logs of decisions and rewards\n",
        "        average_decision_time = np.mean(self.decision_times)\n",
        "        items_crafted = sum(self.inventory.items[sword] for sword in ['BeginnerSword', 'IntermediateSword', 'AdvancedSword'])\n",
        "        liquidity = np.mean([self.marketplace_env.resource_prices[res] for res in ResourceType])\n",
        "\n",
        "        efficiency_metrics = {\n",
        "            'average_decision_time': average_decision_time,\n",
        "            'items_crafted': items_crafted,\n",
        "            'liquidity': liquidity,\n",
        "            'total_reward': self.total_reward\n",
        "        }\n",
        "        return efficiency_metrics\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        # Optional: Implement rendering logic\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1t2QdslQzbpM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XlPhO78M6l2U"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oDYbNsM2k4qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ede9df-2c02-4e60-95d3-b438d455ff79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jXUpPm94k5kO"
      },
      "outputs": [],
      "source": [
        "class RewardLoggerCallback(BaseCallback):\n",
        "    def __init__(self, check_freq):\n",
        "        super(RewardLoggerCallback, self).__init__()\n",
        "        self.check_freq = check_freq\n",
        "        self.rewards = []\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            episode_rewards = self.model.ep_info_buffer\n",
        "            if episode_rewards:\n",
        "                self.rewards.append(episode_rewards[-1]['r'])\n",
        "                print(episode_rewards[-1]['r'])\n",
        "        return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZCKn24I6zdkx",
        "outputId": "fadd12c2-6df0-4e55-af33-3f9af840f9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72.949243\n",
            "57.051772\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 101      |\n",
            "|    ep_rew_mean     | 115      |\n",
            "| time/              |          |\n",
            "|    fps             | 1781     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 16384    |\n",
            "---------------------------------\n",
            "55.714817\n",
            "109.011268\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 78          |\n",
            "|    ep_rew_mean          | 120         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 966         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020828772 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | -0.00447    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25.4        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    value_loss           | 84.2        |\n",
            "-----------------------------------------\n",
            "249.372809\n",
            "93.755972\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 86.1       |\n",
            "|    ep_rew_mean          | 167        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 968        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 50         |\n",
            "|    total_timesteps      | 49152      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01250938 |\n",
            "|    clip_fraction        | 0.198      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.34      |\n",
            "|    explained_variance   | 0.0969     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 67.3       |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0219    |\n",
            "|    value_loss           | 116        |\n",
            "----------------------------------------\n",
            "172.568488\n",
            "348.787864\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 94          |\n",
            "|    ep_rew_mean          | 212         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 971         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 67          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012823022 |\n",
            "|    clip_fraction        | 0.207       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.033       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 94.8        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    value_loss           | 233         |\n",
            "-----------------------------------------\n",
            "288.286813\n",
            "245.175848\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 134         |\n",
            "|    ep_rew_mean          | 354         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 969         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016198872 |\n",
            "|    clip_fraction        | 0.196       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 0.0459      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 158         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0192     |\n",
            "|    value_loss           | 370         |\n",
            "-----------------------------------------\n",
            "792.274787\n",
            "185.928504\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 182         |\n",
            "|    ep_rew_mean          | 589         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 968         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 101         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012175196 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.11       |\n",
            "|    explained_variance   | 0.0277      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 364         |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 539         |\n",
            "-----------------------------------------\n",
            "295.003282\n",
            "463.45415\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 225         |\n",
            "|    ep_rew_mean          | 852         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 963         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 118         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011304773 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.0705      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 419         |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    value_loss           | 899         |\n",
            "-----------------------------------------\n",
            "446.39772\n",
            "246.421409\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 277         |\n",
            "|    ep_rew_mean          | 1.4e+03     |\n",
            "| time/                   |             |\n",
            "|    fps                  | 970         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 135         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014022234 |\n",
            "|    clip_fraction        | 0.232       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.95       |\n",
            "|    explained_variance   | 0.0489      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 502         |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00647    |\n",
            "|    value_loss           | 1.63e+03    |\n",
            "-----------------------------------------\n",
            "603.069488\n",
            "3508.407125\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 321         |\n",
            "|    ep_rew_mean          | 2.28e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 967         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 152         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009461565 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.86       |\n",
            "|    explained_variance   | 0.0455      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.52e+03    |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00509    |\n",
            "|    value_loss           | 1.11e+04    |\n",
            "-----------------------------------------\n",
            "6935.650943\n",
            "22556.515764\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 397          |\n",
            "|    ep_rew_mean          | 4.22e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 971          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 168          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0115896985 |\n",
            "|    clip_fraction        | 0.129        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.77        |\n",
            "|    explained_variance   | 0.0714       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.07e+03     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00865     |\n",
            "|    value_loss           | 2.03e+04     |\n",
            "------------------------------------------\n",
            "328.395534\n",
            "3506.766794\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 450         |\n",
            "|    ep_rew_mean          | 5.8e+03     |\n",
            "| time/                   |             |\n",
            "|    fps                  | 972         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 185         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013415001 |\n",
            "|    clip_fraction        | 0.0957      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.63       |\n",
            "|    explained_variance   | 0.0171      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.74e+04    |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00751    |\n",
            "|    value_loss           | 6.88e+04    |\n",
            "-----------------------------------------\n",
            "19573.095074\n",
            "27412.5027\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 555         |\n",
            "|    ep_rew_mean          | 8.55e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 201         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011217287 |\n",
            "|    clip_fraction        | 0.09        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.47       |\n",
            "|    explained_variance   | 0.0242      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.73e+04    |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00707    |\n",
            "|    value_loss           | 7.86e+04    |\n",
            "-----------------------------------------\n",
            "28177.984268\n",
            "42572.201476\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 642        |\n",
            "|    ep_rew_mean          | 1.12e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 973        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 218        |\n",
            "|    total_timesteps      | 212992     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01122569 |\n",
            "|    clip_fraction        | 0.117      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.39      |\n",
            "|    explained_variance   | 0.0046     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.28e+04   |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.0114    |\n",
            "|    value_loss           | 8.64e+04   |\n",
            "----------------------------------------\n",
            "21094.360267\n",
            "21094.360267\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 711         |\n",
            "|    ep_rew_mean          | 1.31e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 235         |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008968258 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.29       |\n",
            "|    explained_variance   | 0.00191     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.98e+04    |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0126     |\n",
            "|    value_loss           | 1.46e+05    |\n",
            "-----------------------------------------\n",
            "154566.825167\n",
            "122153.668894\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 828         |\n",
            "|    ep_rew_mean          | 1.74e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 976         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 251         |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011802748 |\n",
            "|    clip_fraction        | 0.181       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.18       |\n",
            "|    explained_variance   | 0.000682    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.11e+05    |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    value_loss           | 2.49e+05    |\n",
            "-----------------------------------------\n",
            "19230.874071\n",
            "44233.443463\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 915         |\n",
            "|    ep_rew_mean          | 2.05e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 977         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 268         |\n",
            "|    total_timesteps      | 262144      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019082308 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.96       |\n",
            "|    explained_variance   | 0.00198     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.11e+05    |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0115     |\n",
            "|    value_loss           | 2.45e+05    |\n",
            "-----------------------------------------\n",
            "204823.750223\n",
            "32717.079752\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.06e+03    |\n",
            "|    ep_rew_mean          | 2.63e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 976         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 285         |\n",
            "|    total_timesteps      | 278528      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017818471 |\n",
            "|    clip_fraction        | 0.316       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.95       |\n",
            "|    explained_variance   | 0.00106     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.32e+05    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0339     |\n",
            "|    value_loss           | 2.72e+05    |\n",
            "-----------------------------------------\n",
            "130018.539964\n",
            "130018.539964\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.15e+03    |\n",
            "|    ep_rew_mean          | 2.97e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 976         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 302         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009843455 |\n",
            "|    clip_fraction        | 0.0904      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0.00114     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.36e+05    |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00654    |\n",
            "|    value_loss           | 2.85e+05    |\n",
            "-----------------------------------------\n",
            "86847.014691\n",
            "395771.885806\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.26e+03   |\n",
            "|    ep_rew_mean          | 3.37e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 978        |\n",
            "|    iterations           | 19         |\n",
            "|    time_elapsed         | 318        |\n",
            "|    total_timesteps      | 311296     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01529113 |\n",
            "|    clip_fraction        | 0.326      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.76      |\n",
            "|    explained_variance   | 0.000526   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.35e+05   |\n",
            "|    n_updates            | 180        |\n",
            "|    policy_gradient_loss | -0.0343    |\n",
            "|    value_loss           | 2.83e+05   |\n",
            "----------------------------------------\n",
            "29800.493182\n",
            "264369.699731\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.36e+03    |\n",
            "|    ep_rew_mean          | 3.82e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 334         |\n",
            "|    total_timesteps      | 327680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020028282 |\n",
            "|    clip_fraction        | 0.207       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.000818    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.8e+05     |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0187     |\n",
            "|    value_loss           | 3.66e+05    |\n",
            "-----------------------------------------\n",
            "264369.699731\n",
            "160634.477638\n",
            "393876.55063\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.63e+03    |\n",
            "|    ep_rew_mean          | 4.84e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 351         |\n",
            "|    total_timesteps      | 344064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010223811 |\n",
            "|    clip_fraction        | 0.251       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.00195     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.07e+05    |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.025      |\n",
            "|    value_loss           | 1.98e+05    |\n",
            "-----------------------------------------\n",
            "296036.985902\n",
            "195658.129559\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.73e+03    |\n",
            "|    ep_rew_mean          | 5.31e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 981         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 367         |\n",
            "|    total_timesteps      | 360448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015129967 |\n",
            "|    clip_fraction        | 0.313       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.0025      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.35e+04    |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0351     |\n",
            "|    value_loss           | 2.15e+05    |\n",
            "-----------------------------------------\n",
            "129616.659601\n",
            "283673.205039\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.95e+03   |\n",
            "|    ep_rew_mean          | 6.18e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 983        |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 383        |\n",
            "|    total_timesteps      | 376832     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01925429 |\n",
            "|    clip_fraction        | 0.325      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.62      |\n",
            "|    explained_variance   | 0.00427    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.44e+05   |\n",
            "|    n_updates            | 220        |\n",
            "|    policy_gradient_loss | -0.0305    |\n",
            "|    value_loss           | 3.39e+05   |\n",
            "----------------------------------------\n",
            "283673.205039\n",
            "83093.516588\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.02e+03    |\n",
            "|    ep_rew_mean          | 6.46e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 983         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 399         |\n",
            "|    total_timesteps      | 393216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009779626 |\n",
            "|    clip_fraction        | 0.0955      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.00258     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.41e+05    |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0076     |\n",
            "|    value_loss           | 3.07e+05    |\n",
            "-----------------------------------------\n",
            "83093.516588\n",
            "83093.516588\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.02e+03    |\n",
            "|    ep_rew_mean          | 6.46e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 984         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 416         |\n",
            "|    total_timesteps      | 409600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015618803 |\n",
            "|    clip_fraction        | 0.315       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.00238     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.31e+05    |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0307     |\n",
            "|    value_loss           | 2.95e+05    |\n",
            "-----------------------------------------\n",
            "83093.516588\n",
            "5454.04963\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.08e+03    |\n",
            "|    ep_rew_mean          | 6.78e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 985         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 432         |\n",
            "|    total_timesteps      | 425984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020661987 |\n",
            "|    clip_fraction        | 0.291       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.8e+05     |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0278     |\n",
            "|    value_loss           | 3.99e+05    |\n",
            "-----------------------------------------\n",
            "5454.04963\n",
            "5454.04963\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.08e+03    |\n",
            "|    ep_rew_mean          | 6.78e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 985         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 448         |\n",
            "|    total_timesteps      | 442368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009305556 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0.00137     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.34e+05    |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00971    |\n",
            "|    value_loss           | 2.99e+05    |\n",
            "-----------------------------------------\n",
            "425027.279602\n",
            "425027.279602\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.17e+03    |\n",
            "|    ep_rew_mean          | 7.2e+04     |\n",
            "| time/                   |             |\n",
            "|    fps                  | 984         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 466         |\n",
            "|    total_timesteps      | 458752      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023047654 |\n",
            "|    clip_fraction        | 0.442       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.08e+05    |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0497     |\n",
            "|    value_loss           | 2.44e+05    |\n",
            "-----------------------------------------\n",
            "425027.279602\n",
            "425027.279602\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.17e+03    |\n",
            "|    ep_rew_mean          | 7.2e+04     |\n",
            "| time/                   |             |\n",
            "|    fps                  | 983         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 483         |\n",
            "|    total_timesteps      | 475136      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021034207 |\n",
            "|    clip_fraction        | 0.415       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | 0.00456     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.97e+05    |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0401     |\n",
            "|    value_loss           | 3.9e+05     |\n",
            "-----------------------------------------\n",
            "425027.279602\n",
            "930361.81474\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.38e+03    |\n",
            "|    ep_rew_mean          | 8.12e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 982         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 500         |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019403558 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.66e+05    |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0127     |\n",
            "|    value_loss           | 5.07e+05    |\n",
            "-----------------------------------------\n",
            "930361.81474\n",
            "930361.81474\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.52e+03    |\n",
            "|    ep_rew_mean          | 8.74e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 981         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 517         |\n",
            "|    total_timesteps      | 507904      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007695279 |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.000772    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.46e+04    |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    value_loss           | 1.82e+05    |\n",
            "-----------------------------------------\n",
            "626048.560161\n",
            "626048.560161\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.52e+03    |\n",
            "|    ep_rew_mean          | 8.74e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 981         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 533         |\n",
            "|    total_timesteps      | 524288      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017842732 |\n",
            "|    clip_fraction        | 0.339       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.25       |\n",
            "|    explained_variance   | 0.0114      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.63e+04    |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.0411     |\n",
            "|    value_loss           | 1.18e+05    |\n",
            "-----------------------------------------\n",
            "626048.560161\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 982         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 550         |\n",
            "|    total_timesteps      | 540672      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024160124 |\n",
            "|    clip_fraction        | 0.476       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.25       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.12e+05    |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0547     |\n",
            "|    value_loss           | 2.42e+05    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 983         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 566         |\n",
            "|    total_timesteps      | 557056      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022022557 |\n",
            "|    clip_fraction        | 0.469       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | 0.00813     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.75e+05    |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0465     |\n",
            "|    value_loss           | 3.68e+05    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.77e+03   |\n",
            "|    ep_rew_mean          | 9.83e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 982        |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 583        |\n",
            "|    total_timesteps      | 573440     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02154034 |\n",
            "|    clip_fraction        | 0.224      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.01      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.57e+05   |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | -0.0182    |\n",
            "|    value_loss           | 5.28e+05   |\n",
            "----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 982         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 600         |\n",
            "|    total_timesteps      | 589824      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008208863 |\n",
            "|    clip_fraction        | 0.0584      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.938      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.66e+05    |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.00428    |\n",
            "|    value_loss           | 5.79e+05    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.77e+03   |\n",
            "|    ep_rew_mean          | 9.83e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 982        |\n",
            "|    iterations           | 37         |\n",
            "|    time_elapsed         | 616        |\n",
            "|    total_timesteps      | 606208     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00613171 |\n",
            "|    clip_fraction        | 0.113      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.983     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.16e+05   |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | -0.00763   |\n",
            "|    value_loss           | 2.09e+05   |\n",
            "----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.77e+03   |\n",
            "|    ep_rew_mean          | 9.83e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 983        |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 633        |\n",
            "|    total_timesteps      | 622592     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04278084 |\n",
            "|    clip_fraction        | 0.327      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.07      |\n",
            "|    explained_variance   | 1.19e-07   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.41e+04   |\n",
            "|    n_updates            | 370        |\n",
            "|    policy_gradient_loss | -0.0426    |\n",
            "|    value_loss           | 3.96e+04   |\n",
            "----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 980         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 651         |\n",
            "|    total_timesteps      | 638976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027361494 |\n",
            "|    clip_fraction        | 0.454       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.57e+04    |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.0538     |\n",
            "|    value_loss           | 1.42e+05    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 980         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 668         |\n",
            "|    total_timesteps      | 655360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020589676 |\n",
            "|    clip_fraction        | 0.557       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.38e+05    |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.0621     |\n",
            "|    value_loss           | 3.21e+05    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 980         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 684         |\n",
            "|    total_timesteps      | 671744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028684918 |\n",
            "|    clip_fraction        | 0.452       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.902      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.32e+05    |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.0524     |\n",
            "|    value_loss           | 5.02e+05    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 702         |\n",
            "|    total_timesteps      | 688128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.052437145 |\n",
            "|    clip_fraction        | 0.318       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.682      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.61e+05    |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.0405     |\n",
            "|    value_loss           | 7.54e+05    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.77e+03     |\n",
            "|    ep_rew_mean          | 9.83e+04     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 978          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 719          |\n",
            "|    total_timesteps      | 704512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051584104 |\n",
            "|    clip_fraction        | 0.029        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.581       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.06e+05     |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.0024      |\n",
            "|    value_loss           | 8.12e+05     |\n",
            "------------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.77e+03     |\n",
            "|    ep_rew_mean          | 9.83e+04     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 979          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 736          |\n",
            "|    total_timesteps      | 720896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026418022 |\n",
            "|    clip_fraction        | 0.0913       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.594       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.15e+05     |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.000342    |\n",
            "|    value_loss           | 2.19e+05     |\n",
            "------------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.77e+03   |\n",
            "|    ep_rew_mean          | 9.83e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 978        |\n",
            "|    iterations           | 45         |\n",
            "|    time_elapsed         | 753        |\n",
            "|    total_timesteps      | 737280     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08123471 |\n",
            "|    clip_fraction        | 0.166      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.689     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.1e+03    |\n",
            "|    n_updates            | 440        |\n",
            "|    policy_gradient_loss | -0.0302    |\n",
            "|    value_loss           | 1.7e+04    |\n",
            "----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 978         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 770         |\n",
            "|    total_timesteps      | 753664      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.039348178 |\n",
            "|    clip_fraction        | 0.358       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.846      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.19e+04    |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.047      |\n",
            "|    value_loss           | 4.57e+04    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 2.77e+03  |\n",
            "|    ep_rew_mean          | 9.83e+04  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 978       |\n",
            "|    iterations           | 47        |\n",
            "|    time_elapsed         | 786       |\n",
            "|    total_timesteps      | 770048    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0243543 |\n",
            "|    clip_fraction        | 0.506     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.863    |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.94e+04  |\n",
            "|    n_updates            | 460       |\n",
            "|    policy_gradient_loss | -0.0591   |\n",
            "|    value_loss           | 1.62e+05  |\n",
            "---------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 803         |\n",
            "|    total_timesteps      | 786432      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024975566 |\n",
            "|    clip_fraction        | 0.512       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.813      |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.69e+05    |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.0589     |\n",
            "|    value_loss           | 3.43e+05    |\n",
            "-----------------------------------------\n",
            "1090605.871866\n",
            "1090605.871866\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.77e+03    |\n",
            "|    ep_rew_mean          | 9.83e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 978         |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 820         |\n",
            "|    total_timesteps      | 802816      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.041934416 |\n",
            "|    clip_fraction        | 0.396       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.658      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.39e+05    |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.0488     |\n",
            "|    value_loss           | 5.46e+05    |\n",
            "-----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3.31e+03   |\n",
            "|    ep_rew_mean          | 1.23e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 978        |\n",
            "|    iterations           | 50         |\n",
            "|    time_elapsed         | 837        |\n",
            "|    total_timesteps      | 819200     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09651066 |\n",
            "|    clip_fraction        | 0.217      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.441     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.07e+05   |\n",
            "|    n_updates            | 490        |\n",
            "|    policy_gradient_loss | -0.0332    |\n",
            "|    value_loss           | 8.8e+05    |\n",
            "----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3.31e+03     |\n",
            "|    ep_rew_mean          | 1.23e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 978          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 853          |\n",
            "|    total_timesteps      | 835584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017653158 |\n",
            "|    clip_fraction        | 0.0167       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.341       |\n",
            "|    explained_variance   | 0.000315     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.04e+05     |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.000819    |\n",
            "|    value_loss           | 1.02e+06     |\n",
            "------------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.31e+03    |\n",
            "|    ep_rew_mean          | 1.23e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 870         |\n",
            "|    total_timesteps      | 851968      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006555329 |\n",
            "|    clip_fraction        | 0.0177      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.352      |\n",
            "|    explained_variance   | 0.0377      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.75e+05    |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.000827   |\n",
            "|    value_loss           | 4.77e+05    |\n",
            "-----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3.31e+03   |\n",
            "|    ep_rew_mean          | 1.23e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 978        |\n",
            "|    iterations           | 53         |\n",
            "|    time_elapsed         | 887        |\n",
            "|    total_timesteps      | 868352     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.10572556 |\n",
            "|    clip_fraction        | 0.409      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.631     |\n",
            "|    explained_variance   | -1.55      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.61e+03   |\n",
            "|    n_updates            | 520        |\n",
            "|    policy_gradient_loss | -0.0413    |\n",
            "|    value_loss           | 1.75e+04   |\n",
            "----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.31e+03    |\n",
            "|    ep_rew_mean          | 1.23e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 977         |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 904         |\n",
            "|    total_timesteps      | 884736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.044969637 |\n",
            "|    clip_fraction        | 0.318       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.785      |\n",
            "|    explained_variance   | -0.0068     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.62e+03    |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | -0.0429     |\n",
            "|    value_loss           | 1.86e+04    |\n",
            "-----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.31e+03    |\n",
            "|    ep_rew_mean          | 1.23e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 978         |\n",
            "|    iterations           | 55          |\n",
            "|    time_elapsed         | 920         |\n",
            "|    total_timesteps      | 901120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025767732 |\n",
            "|    clip_fraction        | 0.434       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.815      |\n",
            "|    explained_variance   | -0.00333    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.6e+04     |\n",
            "|    n_updates            | 540         |\n",
            "|    policy_gradient_loss | -0.0534     |\n",
            "|    value_loss           | 4.88e+04    |\n",
            "-----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3.31e+03   |\n",
            "|    ep_rew_mean          | 1.23e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 977        |\n",
            "|    iterations           | 56         |\n",
            "|    time_elapsed         | 938        |\n",
            "|    total_timesteps      | 917504     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02104677 |\n",
            "|    clip_fraction        | 0.574      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.797     |\n",
            "|    explained_variance   | 7.87e-06   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.24e+04   |\n",
            "|    n_updates            | 550        |\n",
            "|    policy_gradient_loss | -0.0634    |\n",
            "|    value_loss           | 2.19e+05   |\n",
            "----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3.31e+03   |\n",
            "|    ep_rew_mean          | 1.23e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 977        |\n",
            "|    iterations           | 57         |\n",
            "|    time_elapsed         | 955        |\n",
            "|    total_timesteps      | 933888     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03163514 |\n",
            "|    clip_fraction        | 0.446      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.696     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.92e+05   |\n",
            "|    n_updates            | 560        |\n",
            "|    policy_gradient_loss | -0.0536    |\n",
            "|    value_loss           | 3.7e+05    |\n",
            "----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 3.31e+03  |\n",
            "|    ep_rew_mean          | 1.23e+05  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 977       |\n",
            "|    iterations           | 58        |\n",
            "|    time_elapsed         | 972       |\n",
            "|    total_timesteps      | 950272    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0516087 |\n",
            "|    clip_fraction        | 0.3       |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.527    |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.73e+05  |\n",
            "|    n_updates            | 570       |\n",
            "|    policy_gradient_loss | -0.0399   |\n",
            "|    value_loss           | 6.15e+05  |\n",
            "---------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3.31e+03   |\n",
            "|    ep_rew_mean          | 1.23e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 975        |\n",
            "|    iterations           | 59         |\n",
            "|    time_elapsed         | 990        |\n",
            "|    total_timesteps      | 966656     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05208272 |\n",
            "|    clip_fraction        | 0.147      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.334     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.36e+05   |\n",
            "|    n_updates            | 580        |\n",
            "|    policy_gradient_loss | -0.0234    |\n",
            "|    value_loss           | 9.82e+05   |\n",
            "----------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3.31e+03     |\n",
            "|    ep_rew_mean          | 1.23e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 975          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 1007         |\n",
            "|    total_timesteps      | 983040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013671364 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.238       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.63e+05     |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    value_loss           | 1e+06        |\n",
            "------------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3.31e+03     |\n",
            "|    ep_rew_mean          | 1.23e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 975          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 1024         |\n",
            "|    total_timesteps      | 999424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008772495 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.244       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.19e+05     |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | 0.000512     |\n",
            "|    value_loss           | 3.61e+05     |\n",
            "------------------------------------------\n",
            "2502686.536853\n",
            "2502686.536853\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.31e+03    |\n",
            "|    ep_rew_mean          | 1.23e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 974         |\n",
            "|    iterations           | 62          |\n",
            "|    time_elapsed         | 1042        |\n",
            "|    total_timesteps      | 1015808     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029177807 |\n",
            "|    clip_fraction        | 0.0478      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.31       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.53e+04    |\n",
            "|    n_updates            | 610         |\n",
            "|    policy_gradient_loss | -0.0155     |\n",
            "|    value_loss           | 8.38e+04    |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "crafting_requirements = {\n",
        "    SwordType.BEGINNER: {ResourceType.WOOD: 1, ResourceType.METAL: 1},\n",
        "    SwordType.INTERMEDIATE: {ResourceType.WOOD: 2, ResourceType.METAL: 2},\n",
        "    SwordType.ADVANCED: {ResourceType.GEM: 1, ResourceType.WOOD: 2, ResourceType.METAL: 2},\n",
        "    SwordType.EPIC: {ResourceType.GEM: 2, ResourceType.WOOD: 2, ResourceType.METAL: 2},\n",
        "    SwordType.ULTIMATE: {ResourceType.GEM: 2, ResourceType.WOOD: 2, ResourceType.METAL: 2, ResourceType.DRAGONSCALE: 1}\n",
        "}\n",
        "\n",
        "reward_logger = RewardLoggerCallback(check_freq=1000)\n",
        "# Instantiate the agent\n",
        "env = make_vec_env(lambda: CraftingSellingEnv(marketplace_env, crafting_requirements), n_envs=8)\n",
        "\n",
        "model = PPO('MlpPolicy', env, verbose=1, clip_range=0.2)\n",
        "\n",
        "# Train the agent\n",
        "model.learn(total_timesteps=int(1e6), callback=reward_logger)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"sac_deepq_bandit\")\n",
        "# Plot the rewards\n",
        "plt.plot(reward_logger.rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Cumulative Reward')\n",
        "plt.title('Training Rewards Over Time')\n",
        "plt.show()\n",
        "\n",
        "# Save the agent\n",
        "model.save(\"ppo_craftingselling\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NX3cE_pbeg55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "2c2adc1a-1fe1-4dcb-8648-338366f50c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
            "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-280efdda4c2a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ],
      "source": [
        "# Load the trained agent (if needed)\n",
        "# model = PPO.load(\"ppo_craftingselling\", env=env)\n",
        "\n",
        "# Test the trained agent\n",
        "obs = env.reset()\n",
        "for i in range(1000):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    env.render()\n",
        "    if dones:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3er3Z8nld-f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA-RvFgnlgNf"
      },
      "outputs": [],
      "source": [
        "prices_before_crash = []\n",
        "prices_after_crash = []\n",
        "\n",
        "def run_simulation(env, num_episodes, crash_at_episode):\n",
        "    for episode in range(num_episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action, _states = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, _ = env.step(action)\n",
        "            # Record the prices at each step\n",
        "            prices_before_crash.append(env.marketplace_env.get_resource_prices())\n",
        "\n",
        "            if episode == crash_at_episode:\n",
        "                env.marketplace_env.simulate_market_crash()\n",
        "\n",
        "        # Record prices after the crash for the remaining episodes\n",
        "        if episode >= crash_at_episode:\n",
        "            prices_after_crash.extend(prices_before_crash[-1:])  # Take the last recorded price in the episode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7qAMLx5lgnC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert recorded prices to a DataFrame for easier plotting if not already in DataFrame format\n",
        "import pandas as pd\n",
        "price_data = pd.DataFrame(prices_before_crash + prices_after_crash, columns=['Wood', 'Metal', 'Gem', 'DragonScale'])\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "for resource in price_data.columns:\n",
        "    plt.plot(price_data[resource], label=resource)\n",
        "\n",
        "plt.title('Market Prices Over Time')\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.axvline(x=crash_at_episode * steps_per_episode, color='red', linestyle='--', label='Market Crash')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+xNhZbC+ODh11eXDGSBBn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}